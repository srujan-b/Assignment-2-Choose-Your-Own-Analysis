{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srujan-b/Assignment-2-Choose-Your-Own-Analysis/blob/main/Validating-Synthetic-Models-as-Surgical-Training-Tools.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting the drive"
      ],
      "metadata": {
        "id": "ED36FRGkipNb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bOL4pPs-fUp-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a919c2c9-2a95-4e26-d5d2-c513a3884a17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract the videos"
      ],
      "metadata": {
        "id": "2bf79GdHzpua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Python code extracts the contents of a ZIP file (\"videos_imra.zip\") to a specified directory (\"/content/drive/MyDrive/ColabNotebooks/videos_imra/\"). It includes error handling to check for ZIP file corruption."
      ],
      "metadata": {
        "id": "A6sqBPF539x9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/ColabNotebooks/videos_imra.zip'\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall('/content/drive/MyDrive/ColabNotebooks/videos_imra/')  # Change the target directory as needed\n",
        "    print(\"Extraction successful.\")\n",
        "except zipfile.BadZipFile:\n",
        "    print(\"The ZIP file appears to be corrupted.\")\n"
      ],
      "metadata": {
        "id": "4m5uaE97fWGT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d34efb3-a59c-465b-b04e-27bbcbe75615"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction successful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Code"
      ],
      "metadata": {
        "id": "W3MmQ2-2zskc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Library Import"
      ],
      "metadata": {
        "id": "6foXs3uyi0fF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "These three lines of code import essential libraries for deep learning (PyTorch and torchvision) and computer vision (OpenCV), setting the foundation for image processing and machine learning tasks."
      ],
      "metadata": {
        "id": "BuOwKGAA4jlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib\n",
        "import seaborn\n",
        "import pandas as pd\n",
        "import yaml\n",
        "import cv2\n",
        "import os\n",
        "from IPython.display import display, HTML\n",
        "import imageio"
      ],
      "metadata": {
        "id": "ZpSdDW_6UwPI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This line of code reads a CSV file named \"imra_suturing_dataset.csv\" located in the specified path into a Pandas DataFrame named \"df\" for further data manipulation and analysis."
      ],
      "metadata": {
        "id": "6w2XI_IC4lX7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IMport df"
      ],
      "metadata": {
        "id": "4ullWLzyi5oR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/ColabNotebooks/videos_imra/videos_imra/imra_suturing_dataset.csv')"
      ],
      "metadata": {
        "id": "-0ZXHviQoThm"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "TchyYdzJ0uaU",
        "outputId": "b9779cf1-248c-4168-a875-385752020512"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID      Typeofsuturing                            videofilepath  \\\n",
              "0  AMRA001            Suturing            /videos_imra/Suturing/Novice/   \n",
              "1  AMRA001  intreputedSuturing  /videos_imra/intreputedSuturing/Novice/   \n",
              "2  AMRA006            Suturing            /videos_imra/Suturing/Novice/   \n",
              "3  AMRA006  intreputedSuturing  /videos_imra/intreputedSuturing/Novice/   \n",
              "4  AMRA007            Suturing            /videos_imra/Suturing/Novice/   \n",
              "\n",
              "                  videofilename Category  \n",
              "0      Novice_dV_001_suture.mp4   Novice  \n",
              "1  Novice_dV_001_interupted.mp4   Novice  \n",
              "2      Novice_dv_006_suture.mp4   Novice  \n",
              "3  Novice_dV_006_interupted.mp4   Novice  \n",
              "4      Novice_dv_007_suture.mp4   Novice  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-42239e05-67a8-4ec9-8216-64aee41c67d6\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Typeofsuturing</th>\n",
              "      <th>videofilepath</th>\n",
              "      <th>videofilename</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMRA001</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Novice/</td>\n",
              "      <td>Novice_dV_001_suture.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMRA001</td>\n",
              "      <td>intreputedSuturing</td>\n",
              "      <td>/videos_imra/intreputedSuturing/Novice/</td>\n",
              "      <td>Novice_dV_001_interupted.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AMRA006</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Novice/</td>\n",
              "      <td>Novice_dv_006_suture.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AMRA006</td>\n",
              "      <td>intreputedSuturing</td>\n",
              "      <td>/videos_imra/intreputedSuturing/Novice/</td>\n",
              "      <td>Novice_dV_006_interupted.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AMRA007</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Novice/</td>\n",
              "      <td>Novice_dv_007_suture.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-42239e05-67a8-4ec9-8216-64aee41c67d6')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-42239e05-67a8-4ec9-8216-64aee41c67d6 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-42239e05-67a8-4ec9-8216-64aee41c67d6');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-fdcdc016-4a80-4f38-9483-39ce5c5386d5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fdcdc016-4a80-4f38-9483-39ce5c5386d5')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-fdcdc016-4a80-4f38-9483-39ce5c5386d5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code iterates through rows in a Pandas DataFrame named 'df' and for each row, it checks and extracts properties (width, height, frame rate, and duration) of a video file specified in the DataFrame, then adds these properties to the DataFrame. If the video file is not found, it marks the properties as 'N/A' and prints a message about the missing file. This process is useful for video analysis and metadata extraction."
      ],
      "metadata": {
        "id": "G4-Zgd6B4yXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the prefix to be added to all file paths\n",
        "prefix = \"/content/drive/MyDrive/ColabNotebooks/videos_imra/\"  # Replace with your actual prefix\n",
        "\n",
        "# Assuming your DataFrame is named 'df'\n",
        "for index, row in df.iterrows():\n",
        "    # Construct video path\n",
        "    video_path = prefix + row['videofilepath'].lstrip('./') + row['videofilename']\n",
        "\n",
        "    # Check if the video file exists at the specified location\n",
        "    if os.path.exists(video_path):\n",
        "        # Open the video file\n",
        "        video = cv2.VideoCapture(video_path)\n",
        "\n",
        "        # Extract video dimensions\n",
        "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "        # Extract frame rate (frames per second)\n",
        "        fps = video.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "        # Extract the duration (time) of the video in seconds\n",
        "        frame_count = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "        duration_sec = frame_count / fps\n",
        "\n",
        "        # Add the extracted properties to the DataFrame\n",
        "        df.at[index, 'Video_Width'] = width\n",
        "        df.at[index, 'Video_Height'] = height\n",
        "        df.at[index, 'Frame_Rate'] = fps\n",
        "        df.at[index, 'Duration_Sec'] = duration_sec\n",
        "\n",
        "        # Release the video capture\n",
        "        video.release()\n",
        "    else:\n",
        "        # Video file not found at the specified location\n",
        "        df.at[index, 'Video_Width'] = 'N/A'\n",
        "        df.at[index, 'Video_Height'] = 'N/A'\n",
        "        df.at[index, 'Frame_Rate'] = 'N/A'\n",
        "        df.at[index, 'Duration_Sec'] = 'N/A'\n",
        "        print(f\"Video not found at location: {video_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pd-An9wSoTk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Category'] == 'Expert'].head()"
      ],
      "metadata": {
        "id": "dbd5mjxboTn8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8d1df45a-9ee6-4fde-8def-167304f688dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID      Typeofsuturing                            videofilepath  \\\n",
              "6  AMRA008            Suturing            /videos_imra/Suturing/Expert/   \n",
              "7  AMRA008  intreputedSuturing  /videos_imra/intreputedSuturing/Expert/   \n",
              "8  AMRA010            Suturing            /videos_imra/Suturing/Expert/   \n",
              "9  AMRA011  intreputedSuturing  /videos_imra/intreputedSuturing/Expert/   \n",
              "\n",
              "                  videofilename Category  Video_Width  Video_Height  \\\n",
              "6      Expert_dV_008_suture.mp4   Expert       1548.0        1080.0   \n",
              "7  Expert_dV_008_interupted.mp4   Expert       1532.0        1080.0   \n",
              "8      Expert_dV_010_suture.mp4   Expert       1548.0        1080.0   \n",
              "9  Expert_dV_010_interupted.mp4   Expert       1532.0        1080.0   \n",
              "\n",
              "   Frame_Rate  Duration_Sec  \n",
              "6        30.0    194.066667  \n",
              "7        30.0    102.533333  \n",
              "8        30.0     77.533333  \n",
              "9        30.0     95.466667  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-58237794-812a-44b6-9ce3-457c2130b1c4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Typeofsuturing</th>\n",
              "      <th>videofilepath</th>\n",
              "      <th>videofilename</th>\n",
              "      <th>Category</th>\n",
              "      <th>Video_Width</th>\n",
              "      <th>Video_Height</th>\n",
              "      <th>Frame_Rate</th>\n",
              "      <th>Duration_Sec</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AMRA008</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Expert/</td>\n",
              "      <td>Expert_dV_008_suture.mp4</td>\n",
              "      <td>Expert</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>194.066667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AMRA008</td>\n",
              "      <td>intreputedSuturing</td>\n",
              "      <td>/videos_imra/intreputedSuturing/Expert/</td>\n",
              "      <td>Expert_dV_008_interupted.mp4</td>\n",
              "      <td>Expert</td>\n",
              "      <td>1532.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>102.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AMRA010</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Expert/</td>\n",
              "      <td>Expert_dV_010_suture.mp4</td>\n",
              "      <td>Expert</td>\n",
              "      <td>1548.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>77.533333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>AMRA011</td>\n",
              "      <td>intreputedSuturing</td>\n",
              "      <td>/videos_imra/intreputedSuturing/Expert/</td>\n",
              "      <td>Expert_dV_010_interupted.mp4</td>\n",
              "      <td>Expert</td>\n",
              "      <td>1532.0</td>\n",
              "      <td>1080.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>95.466667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58237794-812a-44b6-9ce3-457c2130b1c4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-58237794-812a-44b6-9ce3-457c2130b1c4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-58237794-812a-44b6-9ce3-457c2130b1c4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ee100f6f-ceb2-45a4-b8c7-7390a00c8605\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ee100f6f-ceb2-45a4-b8c7-7390a00c8605')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ee100f6f-ceb2-45a4-b8c7-7390a00c8605 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code uses Matplotlib to create a bar chart showing the total video duration for each category in the DataFrame 'df' and labels the plot appropriately for visualizing combined suturing and interrupted suturing video categories."
      ],
      "metadata": {
        "id": "ZEoUDgPO44f6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Group the DataFrame by 'Category' and calculate the sum of duration_sec for each category\n",
        "category_duration = df.groupby('Category')['Duration_Sec'].sum()\n",
        "\n",
        "# Plotting the data\n",
        "plt.figure(figsize=(3, 3))\n",
        "category_duration.plot(kind='bar', color='skyblue')\n",
        "plt.title('Total Video Duration by Category of suturing and interupted suturing combined')\n",
        "plt.xlabel('Category')\n",
        "plt.ylabel('Total Duration (seconds)')\n",
        "plt.xticks(rotation=45)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "bT9iGTuDoTrD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "6f405ccb-466f-4f07-ef87-551262f3ae31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'ID': ['AMRA001', 'AMRA001', 'AMRA008', 'AMRA008'],\n",
        "    'Typeofsuturing': ['Suturing', 'intreputedSuturing', 'Suturing', 'intreputedSuturing'],\n",
        "    'videofilepath': ['/videos_imra/Suturing/Novice/', '/videos_imra/intreputedSuturing/Novice/', '/videos_imra/Suturing/Expert/', '/videos_imra/intreputedSuturing/Expert/'],\n",
        "    'videofilename': ['Novice_dV_001_suture.mp4', 'Novice_dV_001_interupted.mp4', 'Expert_dV_008_suture.mp4', 'Expert_dV_008_interupted.mp4'],\n",
        "    'Category': ['Novice', 'Novice', 'Expert', 'Expert']\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "HAXK9zg1ytGZ",
        "outputId": "d1078629-bc89-4229-a167-1e4255675b04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID      Typeofsuturing                            videofilepath  \\\n",
              "0  AMRA001            Suturing            /videos_imra/Suturing/Novice/   \n",
              "1  AMRA001  intreputedSuturing  /videos_imra/intreputedSuturing/Novice/   \n",
              "2  AMRA008            Suturing            /videos_imra/Suturing/Expert/   \n",
              "3  AMRA008  intreputedSuturing  /videos_imra/intreputedSuturing/Expert/   \n",
              "\n",
              "                  videofilename Category  \n",
              "0      Novice_dV_001_suture.mp4   Novice  \n",
              "1  Novice_dV_001_interupted.mp4   Novice  \n",
              "2      Expert_dV_008_suture.mp4   Expert  \n",
              "3  Expert_dV_008_interupted.mp4   Expert  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-836d0d1b-ae83-4834-aa0d-8e797ae801ea\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Typeofsuturing</th>\n",
              "      <th>videofilepath</th>\n",
              "      <th>videofilename</th>\n",
              "      <th>Category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AMRA001</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Novice/</td>\n",
              "      <td>Novice_dV_001_suture.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>AMRA001</td>\n",
              "      <td>intreputedSuturing</td>\n",
              "      <td>/videos_imra/intreputedSuturing/Novice/</td>\n",
              "      <td>Novice_dV_001_interupted.mp4</td>\n",
              "      <td>Novice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AMRA008</td>\n",
              "      <td>Suturing</td>\n",
              "      <td>/videos_imra/Suturing/Expert/</td>\n",
              "      <td>Expert_dV_008_suture.mp4</td>\n",
              "      <td>Expert</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>AMRA008</td>\n",
              "      <td>intreputedSuturing</td>\n",
              "      <td>/videos_imra/intreputedSuturing/Expert/</td>\n",
              "      <td>Expert_dV_008_interupted.mp4</td>\n",
              "      <td>Expert</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-836d0d1b-ae83-4834-aa0d-8e797ae801ea')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-836d0d1b-ae83-4834-aa0d-8e797ae801ea button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-836d0d1b-ae83-4834-aa0d-8e797ae801ea');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-353b22a4-1440-43ca-968b-5dd45c9be9be\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-353b22a4-1440-43ca-968b-5dd45c9be9be')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-353b22a4-1440-43ca-968b-5dd45c9be9be button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video resizing and stablization"
      ],
      "metadata": {
        "id": "3BjbfxC9jEkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code performs video processing on a set of videos listed in a DataFrame 'df'. It resizes the videos to a specified width and height, applies video stabilization using feature matching and frame alignment, and saves the processed videos to an output directory. The code also checks for existing processed videos to avoid reprocessing."
      ],
      "metadata": {
        "id": "SbyIMoLR5BZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the desired width and height (224x224 pixels)\n",
        "width = 224\n",
        "height = 224\n",
        "\n",
        "# Set the desired frame rate (30 fps)\n",
        "frame_rate = 30\n",
        "\n",
        "# Define the prefix for saving processed videos\n",
        "prefix = \"/content/drive/MyDrive/ColabNotebooks/videos_imra\"  # Replace with your prefix\n",
        "\n",
        "# Define a function to perform feature matching between frames\n",
        "def feature_matching(prev_frame, current_frame):\n",
        "    # Initialize ORB detector\n",
        "    orb = cv2.ORB_create()\n",
        "\n",
        "    # Find the keypoints and descriptors with ORB\n",
        "    kp1, des1 = orb.detectAndCompute(prev_frame, None)\n",
        "    kp2, des2 = orb.detectAndCompute(current_frame, None)\n",
        "\n",
        "    # Create BFMatcher (Brute Force Matcher) object\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    # Match descriptors\n",
        "    matches = bf.match(des1, des2)\n",
        "\n",
        "    # Sort them in ascending order of distance\n",
        "    matches = sorted(matches, key=lambda x: x.distance)\n",
        "\n",
        "    # Get good matches\n",
        "    good_matches = matches[:20]  # Adjust the number of matches as needed\n",
        "\n",
        "    if len(good_matches) >= 4:\n",
        "        # Extract location of good matches\n",
        "        src_pts = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "        dst_pts = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n",
        "\n",
        "        # Estimate affine transformation using RANSAC\n",
        "        M, _ = cv2.estimateAffine2D(src_pts, dst_pts, cv2.RANSAC)\n",
        "\n",
        "        return M\n",
        "\n",
        "    return None\n",
        "\n",
        "# Iterate through the DataFrame and process each video\n",
        "for index, row in df.iterrows():\n",
        "    input_video_path = prefix + row['videofilepath'] + row['videofilename']\n",
        "    output_video_path = prefix + '/pixel_reduced' + row['videofilepath'] + row['videofilename']\n",
        "\n",
        "    # Check if the output directory exists, and create it if not\n",
        "    output_dir = os.path.dirname(output_video_path)\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    # Check if the output video file already exists, and skip processing if it does\n",
        "    if not os.path.exists(output_video_path):\n",
        "        print(f\"Processing video: {input_video_path}\")\n",
        "\n",
        "        # Open the input video file\n",
        "        cap = cv2.VideoCapture(input_video_path)\n",
        "\n",
        "        # Get the original video's frame width, height, and frame rate\n",
        "        original_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "        original_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "        original_frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "\n",
        "        # Create a VideoWriter object to save the processed video\n",
        "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec for MP4 format\n",
        "        out = cv2.VideoWriter(output_video_path, fourcc, frame_rate, (width, height), isColor=True)\n",
        "\n",
        "        # Initialize variables for video stabilization\n",
        "        prev_frame = None\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Resize the frame to the desired width and height\n",
        "            frame = cv2.resize(frame, (width, height))\n",
        "\n",
        "            # Convert the frame to grayscale\n",
        "            gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Video stabilization using feature matching and frame alignment\n",
        "            if prev_frame is not None:\n",
        "                # Estimate the motion transformation matrix\n",
        "                M = feature_matching(prev_frame, gray_frame)\n",
        "\n",
        "                if M is not None:\n",
        "                    # Apply the estimated transformation to the current frame\n",
        "                    result_frame = cv2.warpAffine(frame, M, (width, height), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n",
        "                else:\n",
        "                    result_frame = frame  # If no transformation, keep the frame as is\n",
        "            else:\n",
        "                result_frame = frame  # First frame, no stabilization\n",
        "\n",
        "            # Write the resulting frame to the output video\n",
        "            out.write(result_frame)\n",
        "\n",
        "            # Update the previous frame\n",
        "            prev_frame = gray_frame\n",
        "\n",
        "        # Release video objects\n",
        "        cap.release()\n",
        "        out.release()\n",
        "        print(f\"Video processed and saved to: {output_video_path}\")\n",
        "    else:\n",
        "        print(f\"Video already processed: {output_video_path}\")\n",
        "\n",
        "# Destroy any OpenCV windows if open\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74dr4CFa2GVy",
        "outputId": "05b848f3-9885-40e3-8648-be22c8c26929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing video: /content/drive/MyDrive/ColabNotebooks/videos_imra/videos_imra/Suturing/Novice/Novice_dV_001_suture.mp4\n",
            "Video processed and saved to: /content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/Suturing/Novice/Novice_dV_001_suture.mp4\n",
            "Processing video: /content/drive/MyDrive/ColabNotebooks/videos_imra/videos_imra/intreputedSuturing/Novice/Novice_dV_001_interupted.mp4\n",
            "Video processed and saved to: /content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/intreputedSuturing/Novice/Novice_dV_001_interupted.mp4\n",
            "Processing video: /content/drive/MyDrive/ColabNotebooks/videos_imra/videos_imra/Suturing/Expert/Expert_dV_008_suture.mp4\n",
            "Video processed and saved to: /content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/Suturing/Expert/Expert_dV_008_suture.mp4\n",
            "Processing video: /content/drive/MyDrive/ColabNotebooks/videos_imra/videos_imra/intreputedSuturing/Expert/Expert_dV_008_interupted.mp4\n",
            "Video processed and saved to: /content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/intreputedSuturing/Expert/Expert_dV_008_interupted.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Converting to frames and getting optical flow info"
      ],
      "metadata": {
        "id": "-GO8e0idjP2W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided Python code extracts frames and optical flow from video files and saves them as image files. Here's a summary of the code's functionality:\n",
        "\n",
        "1. The code takes a video file as input and opens it for processing.\n",
        "\n",
        "2. It calculates the original frame rate of the video.\n",
        "\n",
        "3. An output directory is created to store the extracted frames and optical flow images.\n",
        "\n",
        "4. The code uses the TV-L1 optical flow algorithm to calculate optical flow between consecutive frames in the video.\n",
        "\n",
        "5. Frames are resized to a specified dimension (224x224 in this example) if needed.\n",
        "\n",
        "6. Frames are saved as color images (BGR) without converting them to grayscale.\n",
        "\n",
        "7. Optical flow is computed and saved as separate flow_x and flow_y components.\n",
        "\n",
        "8. The code processes the video, skipping frames to match the desired frame rate specified (default is 10 frames per second).\n",
        "\n",
        "9. The processed video is released, and the code completes its execution.\n",
        "\n",
        "The modified code ensures that the frames are saved in color, preserving the original BGR color information. This code can be useful for various computer vision and video analysis tasks that require frame and optical flow data in color format."
      ],
      "metadata": {
        "id": "m2y0or7Q5Ol7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = {\n",
        "    'ID': [ 'AMRA008'],\n",
        "    'Typeofsuturing': ['intreputedSuturing'],\n",
        "    'videofilepath': [ '/videos_imra/intreputedSuturing/Expert/'],\n",
        "    'videofilename': [ 'Expert_dV_008_interupted.mp4'],\n",
        "    'Category': ['Expert']\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "lyT9w2R7HGV6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import os\n",
        "from multiprocessing import Pool\n",
        "\n",
        "def extract_frames_and_optical_flow(video_path, output_directory, frame_rate=10):\n",
        "\n",
        "\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # Get the original frame rate\n",
        "    original_frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
        "    print(f\"Original frame rate: {original_frame_rate} FPS\")\n",
        "\n",
        "    # Extract the video file name without extension\n",
        "    video_name = os.path.splitext(os.path.basename(video_path))[0]\n",
        "\n",
        "    # Create an output directory for frames\n",
        "    frames_directory = os.path.join(output_directory, \"frames\", video_name)\n",
        "    os.makedirs(frames_directory, exist_ok=True)\n",
        "    print(f\"Frames directory: {frames_directory}\")\n",
        "\n",
        "    # Create an output directory for optical flow images\n",
        "    optical_flow_directory = os.path.join(output_directory,\"opticalFlow\", video_name)\n",
        "    os.makedirs(optical_flow_directory, exist_ok=True)\n",
        "    print(f\"Optical flow directory: {optical_flow_directory}\")\n",
        "\n",
        "    # Initialize variables for TV-L1 optical flow\n",
        "    prev_frame = None\n",
        "    optical_flow = cv2.optflow.createOptFlow_DualTVL1()\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Resize the frame if needed\n",
        "        frame_resized = cv2.resize(frame, (224, 224))  # Change dimensions as needed\n",
        "\n",
        "        if prev_frame is not None:\n",
        "            # Calculate TV-L1 optical flow\n",
        "            flow = optical_flow.calc(cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY),\n",
        "                                     cv2.cvtColor(frame_resized, cv2.COLOR_BGR2GRAY), None)\n",
        "\n",
        "            # Save the optical flow as separate x and y components\n",
        "            flow_x = flow[..., 0]\n",
        "            flow_y = flow[..., 1]\n",
        "\n",
        "            flow_x_path = os.path.join(optical_flow_directory, f'flow_x_{frame_count:05d}.jpg')\n",
        "            flow_y_path = os.path.join(optical_flow_directory, f'flow_y_{frame_count:05d}.jpg')\n",
        "\n",
        "            cv2.imwrite(flow_x_path, flow_x)\n",
        "            cv2.imwrite(flow_y_path, flow_y)\n",
        "\n",
        "        frame_path = os.path.join(frames_directory, f'frame_{frame_count:05d}.jpg')\n",
        "        cv2.imwrite(frame_path, frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "        # Set the previous frame for the next iteration\n",
        "        prev_frame = frame_resized\n",
        "\n",
        "        # Skip frames to match the desired frame rate\n",
        "        skip_frames = int(original_frame_rate / frame_rate) - 1\n",
        "        for _ in range(skip_frames):\n",
        "            ret, _ = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "    # Release video object\n",
        "    cap.release()\n",
        "    print(f\"Video processing complete for {video_name}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Set the prefix to your provided path\n",
        "    prefix = \"/content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced\"\n",
        "\n",
        "    # Create a list of video information tuples\n",
        "    video_info_list = [\n",
        "        (\n",
        "            f\"{prefix}{row['videofilepath']}{row['videofilename']}\",\n",
        "            f\"{prefix}{row['videofilepath']}\",\n",
        "            30 if \"expert\" in row['videofilename'].lower() else 10\n",
        "        ) for index, row in df.iterrows()\n",
        "    ]\n",
        "\n",
        "    # Set the number of CPU cores to use for multiprocessing\n",
        "    num_cpus = os.cpu_count()\n",
        "    print(f\"Number of CPU cores: {num_cpus}\")\n",
        "\n",
        "    # Create a multiprocessing pool and map the function to process videos\n",
        "    with Pool(num_cpus) as pool:\n",
        "        pool.starmap(extract_frames_and_optical_flow, video_info_list)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JLO78ahF-u3",
        "outputId": "476111e7-1a0c-446a-86f9-e50dd6554fa7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('/content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/intreputedSuturing/Expert/Expert_dV_008_interupted.mp4', '/content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/intreputedSuturing/Expert/', 30)]\n",
            "Number of CPU cores: 40\n",
            "Original frame rate: 30 FPS\n",
            "Frames directory: /content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/intreputedSuturing/Expert/frames/Expert_dV_008_interupted\n",
            "Optical flow directory: /content/drive/MyDrive/ColabNotebooks/videos_imra/pixel_reduced/videos_imra/intreputedSuturing/Expert/opticalFlow/Expert_dV_008_interupted\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment\n",
        "\n",
        "task_choices = ['Suturing', 'Needle_Passing', 'Knot_Tying']\n",
        "task = 'Suturing'  # Default task\n",
        "\n",
        "eval_scheme_choices = ['LOSO', 'LOUO']\n",
        "eval_scheme = 'LOSO'  # Default evaluation scheme\n",
        "\n",
        "split = None  # Define the appropriate value\n",
        "\n",
        "modality_choices = ['RGB', 'Flow']\n",
        "modality = 'RGB'  # Default modality\n",
        "\n",
        "# Data\n",
        "\n",
        "data_path = \"?\"  # Replace \"?\" with the actual path\n",
        "video_lists_dir = \"./Splits/{}/\"  # Replace \"{}\" with the actual values\n",
        "video_sampling_step = 3  # Default video sampling step\n",
        "three_channel_flow = False  # Default value\n",
        "do_horizontal_flip = True  # Default value\n",
        "data_preloading = True  # Default value\n",
        "\n",
        "# Model\n",
        "\n",
        "num_cls_Kinetics = 400\n",
        "\n",
        "snippet_length = 64  # Default value\n",
        "dropout = 0.7  # Default value\n",
        "num_segments = 10  # Default value\n",
        "pretrain_path = None  # Default value\n",
        "\n",
        "# Training\n",
        "\n",
        "workers = 4  # Default value\n",
        "epochs = 1200  # Default value\n",
        "batch_size = 2  # Default value\n",
        "lr = 0.00001  # Default value\n",
        "eval_freq = 10  # Default value\n",
        "save_freq = 100  # Default value\n",
        "output_path = \"?\"  # Replace \"?\" with the actual path\n"
      ],
      "metadata": {
        "id": "kGEP6bKd6_I5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os.path\n",
        "import datetime\n",
        "import string\n",
        "import torch\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "vBCOTyx0R5oq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class ConsensusModule(torch.nn.Module):\n",
        "    def __init__(self, dim=1):\n",
        "        super(ConsensusModule, self).__init__()\n",
        "        self.dim = dim\n",
        "        self.shape = None\n",
        "\n",
        "    def forward(self, input_tensor):\n",
        "        self.shape = input_tensor.size()\n",
        "        output = input_tensor.mean(dim=self.dim, keepdim=True)\n",
        "        return output\n",
        "\n",
        "    def backward(self, grad_output):\n",
        "        grad_in = grad_output.expand(self.shape) / float(self.shape[self.dim])\n",
        "        return grad_in\n"
      ],
      "metadata": {
        "id": "jWCRAiunSSAX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code defines the architecture of the Inception I3D (Inception-v1) model, which is a deep convolutional neural network used for action recognition in videos. This model is a modified version of the Inception architecture, designed specifically for 3D video data. Here are the key components of the code:\n",
        "\n",
        "1. **MaxPool3dSamePadding:** This is a custom MaxPool3D layer with padding that ensures the output size matches the input size spatially. It calculates padding dynamically based on the input and stride, ensuring that the spatial dimensions are preserved.\n",
        "\n",
        "2. **Unit3D:** This class defines a basic 3D convolutional unit with options for batch normalization, activation functions, and bias usage. It is a fundamental building block used in the Inception I3D model.\n",
        "\n",
        "3. **InceptionModule:** This module represents an Inception module, which is a combination of 3D convolutional filters with different kernel sizes. It is used to capture features at multiple scales in the video data.\n",
        "\n",
        "4. **InceptionI3d:** The main Inception I3D model is constructed here. It consists of multiple Inception modules, max-pooling layers, and a final classification layer. The model can be configured for a specific number of output classes, and it includes dropout for regularization.\n",
        "\n",
        "5. **Forward and Feature Extraction:** The forward pass of the model is defined, which computes the logits for classification. Additionally, a feature extraction method is provided to extract features from intermediate layers of the model.\n",
        "\n",
        "In summary, this code defines the architecture of the Inception I3D model, a powerful deep learning model for video-based action recognition. It can be used for tasks such as recognizing human actions in videos or analyzing video data in various applications."
      ],
      "metadata": {
        "id": "Anfc-8xPgEHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class MaxPool3dSamePadding(nn.MaxPool3d):\n",
        "\n",
        "    def compute_pad(self, dim, s):\n",
        "        if s % self.stride[dim] == 0:\n",
        "            return max(self.kernel_size[dim] - self.stride[dim], 0)\n",
        "        else:\n",
        "            return max(self.kernel_size[dim] - (s % self.stride[dim]), 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # compute 'same' padding\n",
        "        (batch, channel, t, h, w) = x.size()\n",
        "        #print t,h,w\n",
        "        out_t = np.ceil(float(t) / float(self.stride[0]))\n",
        "        out_h = np.ceil(float(h) / float(self.stride[1]))\n",
        "        out_w = np.ceil(float(w) / float(self.stride[2]))\n",
        "        #print out_t, out_h, out_w\n",
        "        pad_t = self.compute_pad(0, t)\n",
        "        pad_h = self.compute_pad(1, h)\n",
        "        pad_w = self.compute_pad(2, w)\n",
        "        #print pad_t, pad_h, pad_w\n",
        "\n",
        "        pad_t_f = pad_t // 2\n",
        "        pad_t_b = pad_t - pad_t_f\n",
        "        pad_h_f = pad_h // 2\n",
        "        pad_h_b = pad_h - pad_h_f\n",
        "        pad_w_f = pad_w // 2\n",
        "        pad_w_b = pad_w - pad_w_f\n",
        "\n",
        "        pad = (pad_w_f, pad_w_b, pad_h_f, pad_h_b, pad_t_f, pad_t_b)\n",
        "        #print x.size()\n",
        "        #print pad\n",
        "        x = F.pad(x, pad)\n",
        "        return super(MaxPool3dSamePadding, self).forward(x)\n",
        "\n",
        "\n",
        "class Unit3D(nn.Module):\n",
        "\n",
        "    def __init__(self, in_channels,\n",
        "                 output_channels,\n",
        "                 kernel_shape=(1, 1, 1),\n",
        "                 stride=(1, 1, 1),\n",
        "                 padding=0,\n",
        "                 activation_fn=F.relu,\n",
        "                 use_batch_norm=True,\n",
        "                 use_bias=False,\n",
        "                 name='unit_3d'):\n",
        "\n",
        "        \"\"\"Initializes Unit3D module.\"\"\"\n",
        "        super(Unit3D, self).__init__()\n",
        "\n",
        "        self._output_channels = output_channels\n",
        "        self._kernel_shape = kernel_shape\n",
        "        self._stride = stride\n",
        "        self._use_batch_norm = use_batch_norm\n",
        "        self._activation_fn = activation_fn\n",
        "        self._use_bias = use_bias\n",
        "        self.name = name\n",
        "        self.padding = padding\n",
        "\n",
        "        self.conv3d = nn.Conv3d(in_channels=in_channels,\n",
        "                                out_channels=self._output_channels,\n",
        "                                kernel_size=self._kernel_shape,\n",
        "                                stride=self._stride,\n",
        "                                padding=0, # we always want padding to be 0 here. We will dynamically pad based on input size in forward function\n",
        "                                bias=self._use_bias)\n",
        "\n",
        "        if self._use_batch_norm:\n",
        "            self.bn = nn.BatchNorm3d(self._output_channels, eps=0.001, momentum=0.01)\n",
        "\n",
        "    def compute_pad(self, dim, s):\n",
        "        if s % self._stride[dim] == 0:\n",
        "            return max(self._kernel_shape[dim] - self._stride[dim], 0)\n",
        "        else:\n",
        "            return max(self._kernel_shape[dim] - (s % self._stride[dim]), 0)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # compute 'same' padding\n",
        "        (batch, channel, t, h, w) = x.size()\n",
        "        #print t,h,w\n",
        "        out_t = np.ceil(float(t) / float(self._stride[0]))\n",
        "        out_h = np.ceil(float(h) / float(self._stride[1]))\n",
        "        out_w = np.ceil(float(w) / float(self._stride[2]))\n",
        "        #print out_t, out_h, out_w\n",
        "        pad_t = self.compute_pad(0, t)\n",
        "        pad_h = self.compute_pad(1, h)\n",
        "        pad_w = self.compute_pad(2, w)\n",
        "        #print pad_t, pad_h, pad_w\n",
        "\n",
        "        pad_t_f = pad_t // 2\n",
        "        pad_t_b = pad_t - pad_t_f\n",
        "        pad_h_f = pad_h // 2\n",
        "        pad_h_b = pad_h - pad_h_f\n",
        "        pad_w_f = pad_w // 2\n",
        "        pad_w_b = pad_w - pad_w_f\n",
        "\n",
        "        pad = (pad_w_f, pad_w_b, pad_h_f, pad_h_b, pad_t_f, pad_t_b)\n",
        "        #print x.size()\n",
        "        #print pad\n",
        "        x = F.pad(x, pad)\n",
        "        #print x.size()\n",
        "\n",
        "        x = self.conv3d(x)\n",
        "        if self._use_batch_norm:\n",
        "            x = self.bn(x)\n",
        "        if self._activation_fn is not None:\n",
        "            x = self._activation_fn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "\n",
        "class InceptionModule(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, name):\n",
        "        super(InceptionModule, self).__init__()\n",
        "\n",
        "        self.b0 = Unit3D(in_channels=in_channels, output_channels=out_channels[0], kernel_shape=[1, 1, 1], padding=0,\n",
        "                         name=name+'/Branch_0/Conv3d_0a_1x1')\n",
        "        self.b1a = Unit3D(in_channels=in_channels, output_channels=out_channels[1], kernel_shape=[1, 1, 1], padding=0,\n",
        "                          name=name+'/Branch_1/Conv3d_0a_1x1')\n",
        "        self.b1b = Unit3D(in_channels=out_channels[1], output_channels=out_channels[2], kernel_shape=[3, 3, 3],\n",
        "                          name=name+'/Branch_1/Conv3d_0b_3x3')\n",
        "        self.b2a = Unit3D(in_channels=in_channels, output_channels=out_channels[3], kernel_shape=[1, 1, 1], padding=0,\n",
        "                          name=name+'/Branch_2/Conv3d_0a_1x1')\n",
        "        self.b2b = Unit3D(in_channels=out_channels[3], output_channels=out_channels[4], kernel_shape=[3, 3, 3],\n",
        "                          name=name+'/Branch_2/Conv3d_0b_3x3')\n",
        "        self.b3a = MaxPool3dSamePadding(kernel_size=[3, 3, 3],\n",
        "                                stride=(1, 1, 1), padding=0)\n",
        "        self.b3b = Unit3D(in_channels=in_channels, output_channels=out_channels[5], kernel_shape=[1, 1, 1], padding=0,\n",
        "                          name=name+'/Branch_3/Conv3d_0b_1x1')\n",
        "        self.name = name\n",
        "\n",
        "    def forward(self, x):\n",
        "        b0 = self.b0(x)\n",
        "        b1 = self.b1b(self.b1a(x))\n",
        "        b2 = self.b2b(self.b2a(x))\n",
        "        b3 = self.b3b(self.b3a(x))\n",
        "        return torch.cat([b0,b1,b2,b3], dim=1)\n",
        "\n",
        "\n",
        "class InceptionI3d(nn.Module):\n",
        "    \"\"\"Inception-v1 I3D architecture.\n",
        "    The model is introduced in:\n",
        "        Quo Vadis, Action Recognition? A New Model and the Kinetics Dataset\n",
        "        Joao Carreira, Andrew Zisserman\n",
        "        https://arxiv.org/pdf/1705.07750v1.pdf.\n",
        "    See also the Inception architecture, introduced in:\n",
        "        Going deeper with convolutions\n",
        "        Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed,\n",
        "        Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich.\n",
        "        http://arxiv.org/pdf/1409.4842v1.pdf.\n",
        "    \"\"\"\n",
        "\n",
        "    # Endpoints of the model in order. During construction, all the endpoints up\n",
        "    # to a designated `final_endpoint` are returned in a dictionary as the\n",
        "    # second return value.\n",
        "    VALID_ENDPOINTS = (\n",
        "        'Conv3d_1a_7x7',\n",
        "        'MaxPool3d_2a_3x3',\n",
        "        'Conv3d_2b_1x1',\n",
        "        'Conv3d_2c_3x3',\n",
        "        'MaxPool3d_3a_3x3',\n",
        "        'Mixed_3b',\n",
        "        'Mixed_3c',\n",
        "        'MaxPool3d_4a_3x3',\n",
        "        'Mixed_4b',\n",
        "        'Mixed_4c',\n",
        "        'Mixed_4d',\n",
        "        'Mixed_4e',\n",
        "        'Mixed_4f',\n",
        "        'MaxPool3d_5a_2x2',\n",
        "        'Mixed_5b',\n",
        "        'Mixed_5c',\n",
        "        'Logits',\n",
        "        'Predictions',\n",
        "    )\n",
        "\n",
        "    def __init__(self, num_classes=400, spatial_squeeze=True,\n",
        "                 final_endpoint='Logits', name='inception_i3d', in_channels=3, dropout_keep_prob=0.5):\n",
        "        \"\"\"Initializes I3D model instance.\n",
        "        Args:\n",
        "          num_classes: The number of outputs in the logit layer (default 400, which\n",
        "              matches the Kinetics dataset).\n",
        "          spatial_squeeze: Whether to squeeze the spatial dimensions for the logits\n",
        "              before returning (default True).\n",
        "          final_endpoint: The model contains many possible endpoints.\n",
        "              `final_endpoint` specifies the last endpoint for the model to be built\n",
        "              up to. In addition to the output at `final_endpoint`, all the outputs\n",
        "              at endpoints up to `final_endpoint` will also be returned, in a\n",
        "              dictionary. `final_endpoint` must be one of\n",
        "              InceptionI3d.VALID_ENDPOINTS (default 'Logits').\n",
        "          name: A string (optional). The name of this module.\n",
        "        Raises:\n",
        "          ValueError: if `final_endpoint` is not recognized.\n",
        "        \"\"\"\n",
        "\n",
        "        if final_endpoint not in self.VALID_ENDPOINTS:\n",
        "            raise ValueError('Unknown final endpoint %s' % final_endpoint)\n",
        "\n",
        "        super(InceptionI3d, self).__init__()\n",
        "        self._num_classes = num_classes\n",
        "        self._spatial_squeeze = spatial_squeeze\n",
        "        self._final_endpoint = final_endpoint\n",
        "        self.logits = None\n",
        "\n",
        "        if self._final_endpoint not in self.VALID_ENDPOINTS:\n",
        "            raise ValueError('Unknown final endpoint %s' % self._final_endpoint)\n",
        "\n",
        "        self.end_points = {}\n",
        "        end_point = 'Conv3d_1a_7x7'\n",
        "        self.end_points[end_point] = Unit3D(in_channels=in_channels, output_channels=64, kernel_shape=[7, 7, 7],\n",
        "                                            stride=(2, 2, 2), padding=(3,3,3),  name=name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'MaxPool3d_2a_3x3'\n",
        "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2),\n",
        "                                                             padding=0)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Conv3d_2b_1x1'\n",
        "        self.end_points[end_point] = Unit3D(in_channels=64, output_channels=64, kernel_shape=[1, 1, 1], padding=0,\n",
        "                                       name=name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Conv3d_2c_3x3'\n",
        "        self.end_points[end_point] = Unit3D(in_channels=64, output_channels=192, kernel_shape=[3, 3, 3], padding=1,\n",
        "                                       name=name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'MaxPool3d_3a_3x3'\n",
        "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[1, 3, 3], stride=(1, 2, 2),\n",
        "                                                             padding=0)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_3b'\n",
        "        self.end_points[end_point] = InceptionModule(192, [64,96,128,16,32,32], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_3c'\n",
        "        self.end_points[end_point] = InceptionModule(256, [128,128,192,32,96,64], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'MaxPool3d_4a_3x3'\n",
        "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[3, 3, 3], stride=(2, 2, 2),\n",
        "                                                             padding=0)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_4b'\n",
        "        self.end_points[end_point] = InceptionModule(128+192+96+64, [192,96,208,16,48,64], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_4c'\n",
        "        self.end_points[end_point] = InceptionModule(192+208+48+64, [160,112,224,24,64,64], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_4d'\n",
        "        self.end_points[end_point] = InceptionModule(160+224+64+64, [128,128,256,24,64,64], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_4e'\n",
        "        self.end_points[end_point] = InceptionModule(128+256+64+64, [112,144,288,32,64,64], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_4f'\n",
        "        self.end_points[end_point] = InceptionModule(112+288+64+64, [256,160,320,32,128,128], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'MaxPool3d_5a_2x2'\n",
        "        self.end_points[end_point] = MaxPool3dSamePadding(kernel_size=[2, 2, 2], stride=(2, 2, 2),\n",
        "                                                             padding=0)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_5b'\n",
        "        self.end_points[end_point] = InceptionModule(256+320+128+128, [256,160,320,32,128,128], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Mixed_5c'\n",
        "        self.end_points[end_point] = InceptionModule(256+320+128+128, [384,192,384,48,128,128], name+end_point)\n",
        "        if self._final_endpoint == end_point: return\n",
        "\n",
        "        end_point = 'Logits'\n",
        "        self.avg_pool = nn.AvgPool3d(kernel_size=[2, 7, 7],\n",
        "                                     stride=(1, 1, 1))\n",
        "        self.dropout = nn.Dropout(dropout_keep_prob)\n",
        "        self.logits = Unit3D(in_channels=384+384+128+128, output_channels=self._num_classes,\n",
        "                             kernel_shape=[1, 1, 1],\n",
        "                             padding=0,\n",
        "                             activation_fn=None,\n",
        "                             use_batch_norm=False,\n",
        "                             use_bias=True,\n",
        "                             name='logits')\n",
        "\n",
        "        self.build()\n",
        "\n",
        "\n",
        "    def replace_logits(self, num_classes):\n",
        "        self._num_classes = num_classes\n",
        "        self.logits = Unit3D(in_channels=384+384+128+128, output_channels=self._num_classes,\n",
        "                             kernel_shape=[1, 1, 1],\n",
        "                             padding=0,\n",
        "                             activation_fn=None,\n",
        "                             use_batch_norm=False,\n",
        "                             use_bias=True,\n",
        "                             name='logits')\n",
        "\n",
        "    def set_dropout(self, dropout):\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def build(self):\n",
        "        for k in self.end_points.keys():\n",
        "            self.add_module(k, self.end_points[k])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for end_point in self.VALID_ENDPOINTS:\n",
        "            if end_point in self.end_points:\n",
        "                x = self._modules[end_point](x) # use _modules to work with dataparallel\n",
        "\n",
        "        x = self.logits(self.dropout(self.avg_pool(x)))\n",
        "        if self._spatial_squeeze:\n",
        "            logits = x.squeeze(3).squeeze(3)  # tensor B x C x T\n",
        "\n",
        "        # avgpooling along temporal dimension\n",
        "        logits = torch.mean(logits, 2)\n",
        "\n",
        "        return logits\n",
        "\n",
        "\n",
        "    def extract_features(self, x):\n",
        "        for end_point in self.VALID_ENDPOINTS:\n",
        "            if end_point in self.end_points:\n",
        "                x = self._modules[end_point](x)\n",
        "        return self.avg_pool(x)\n"
      ],
      "metadata": {
        "id": "fvAW6ykTULEd"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gOloyOPefzJ1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}